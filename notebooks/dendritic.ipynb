{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f4VG8OIMM0b8"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "app = \"/app\"\n",
    "if app not in sys.path:\n",
    "    sys.path.append(app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3k2okHqDHDSn"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch import optim\n",
    "from torch.nn import Parameter, GELU, Tanh, Sigmoid, Linear, Conv2d\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "import plotly.express as px\n",
    "from plotly import graph_objects as go\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e9o_iZ9wHr7L"
   },
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gi6hOrxfM3Wz"
   },
   "source": [
    "# A 'dendritic' clustering layer\n",
    "\n",
    "Inspired by Larkum ME, 2022, \"Are Dendrites Conceptually Useful, Neuroscience https://doi.org/10.1016/j.neuroscience.2022.03.008\n",
    "\n",
    "A 'dendritic' fully connected layer extends the classical fully connected `Linear` layer. It usess a convolution filter `conv_filter` to aggregate the activity of neighbouring synapses. The filter is moved along the sequence of synapses with the indicated `stride`. Note that this is a **fixed filter** -- it is NOT a learnable convolution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7vDa0xsGMtdp"
   },
   "source": [
    "# Toy example with simple classification task by a 2-layer MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B3t_HJBCM-Wz"
   },
   "source": [
    "We create a dataset using sklean `make_moons` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JThjwRq6HO4s"
   },
   "outputs": [],
   "source": [
    "X, y = make_moons(n_samples=1000, noise=0.2, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2zQgcCphHepz"
   },
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.int64)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rYaNFYB_NDhl"
   },
   "source": [
    "This is what it looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "id": "zkl58MGcHfnh",
    "outputId": "82cead5c-997f-4214-966d-d12bd6b28bcb"
   },
   "outputs": [],
   "source": [
    "px.scatter(\n",
    "    x=X[:, 0], y=X[:, 1],\n",
    "    color=y.astype(str),\n",
    "    labels={'color': 'Class'},\n",
    "    width=500, height=500,\n",
    "    title='2D Classification Dataset Created by make_moons'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-QvoFq1jNGI3"
   },
   "source": [
    "We convert this into a torch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cSwwMsqZHgoN"
   },
   "outputs": [],
   "source": [
    "train_data = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_data, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zqxwDbSENRkl"
   },
   "source": [
    "Define the model as a 2-layer MLP. The first layer is a normal `Linear` module wich expands the original dimension. The second layer is the 'dendritic' layer. It usess a convolution filter to aggregate the activity of neighbouring synapses. The filter is moved along the sequence of synapses with the indicated stride. This is a **fixed filter** -- it is NOT a learnable convolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7HOEKGvDHjjJ"
   },
   "outputs": [],
   "source": [
    "class dMLP(nn.Module):\n",
    "    \"\"\"'dendritic' MLP with 2 hidden layers, the first classic to expand,\n",
    "    the next dendritic to integrate.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, stride, conv_filter):\n",
    "        super(dMLP, self).__init__()\n",
    "        self.stride = stride\n",
    "        self.conv_filter = conv_filter\n",
    "        self.act_fn = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(2, 10)\n",
    "        self.fc2 = dd.DendriticFullyConnected(10, 2, conv_filter=self.conv_filter, stride=self.stride)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act_fn(self.fc1(x))\n",
    "        x, state2 = self.fc2(x)\n",
    "        return x, (None, state2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "baZZqPR6NmZU"
   },
   "source": [
    "For comparison, a similar classical MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lLLvRNcbHlDZ"
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    \"\"\"Classical MLP with 2 layers\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 10)\n",
    "        self.fc2 = nn.Linear(10, 2)\n",
    "        self.act_fn1 = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act_fn1((self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x, None  # for compatibility with dMLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gdQ5Eg8DQe69"
   },
   "source": [
    "A simple training loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jjTBlOoTHmLZ",
    "outputId": "0e129c9f-67c5-437b-f213-f1b7a5d71468"
   },
   "outputs": [],
   "source": [
    "\n",
    "# this was an attempt to include a constraint to clamp the state to a given upstate\n",
    "# it does not seem to help so far\n",
    "# def loss_fn(outputs, states, labels):\n",
    "#     alpha = 0.5  # state regularization coefficient\n",
    "#     up_state = 0.5  # upper bound for state regularization\n",
    "#     # include a constraint on the state to encourage clamping it\n",
    "#     # to up_state\n",
    "#     if states is not None:\n",
    "#         states = [torch.relu(s - up_state).mean() for s in states]\n",
    "#         state_regul = sum(states) / len(states)\n",
    "#     else:\n",
    "#         state_regul = torch.tensor(0)\n",
    "#     loss = criterion(outputs, labels) + alpha * state_regul\n",
    "#     return loss, state_regul\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "\n",
    "    def __init__(self, model, train_loader, testdata):\n",
    "      self.model = model\n",
    "      self.criterion = nn.CrossEntropyLoss()\n",
    "      self.train_loader = train_loader\n",
    "      self.X_test = testdata[0]\n",
    "      self.y_test = testdata[1]\n",
    "\n",
    "    def train(self, epochs: int, lr: float):\n",
    "        writer = SummaryWriter()  # open new writer --> /runs\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "        for epoch in tqdm(range(epochs)):\n",
    "            for inputs, labels in self.train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs, states = self.model(inputs)\n",
    "                loss = self.criterion(outputs, labels)  # loss_fn(outputs, states, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                self.log(loss, epoch, writer)\n",
    "        print(f\"Done at epoch {epoch}, Loss: {loss.item()}\")\n",
    "        self.accuracy()\n",
    "        writer.close()\n",
    "\n",
    "    def log(self, loss, epoch, writer):\n",
    "        # write to tensorboard\n",
    "        writer.add_scalar(\"Loss/train\", loss.data, epoch)\n",
    "        # loss on Trainset (we are lazy and don't use a separate validation set)\n",
    "        with torch.no_grad():\n",
    "            outputs, states = self.model(self.X_test)\n",
    "            valid_loss = self.criterion(outputs, self.y_test)\n",
    "        writer.add_scalar(\"Loss/valid\", valid_loss, epoch)\n",
    "\n",
    "    def accuracy(self):\n",
    "        # checking accuracy quickly\n",
    "        with torch.no_grad():\n",
    "            outputs, states = self.model(self.X_test)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            accuracy = (predicted == self.y_test).sum().item() / len(self.y_test)\n",
    "        print(f'Accuracy: {accuracy}')\n",
    "\n",
    "# new model\n",
    "stride=2\n",
    "conv_filter = torch.tensor([[[0.33]* 3]])\n",
    "# model = dMLP(stride=stride, conv_filter=conv_filter)\n",
    "model = MLP()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# train\n",
    "trainer = Trainer(model, train_loader, (X_test, y_test))\n",
    "trainer.train(epochs=1000, lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# launch tensorboard\n",
    "%tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qSEAtmI9QnOZ"
   },
   "source": [
    "Visualization of the weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "SnSdl3ouC1Dp",
    "outputId": "11598bf0-c520-4fe0-d5ad-65ae0555cfe0"
   },
   "outputs": [],
   "source": [
    "px.imshow(\n",
    "    dict(model.named_modules())['fc1'].weight.T.data,\n",
    "    width=1000, aspect='auto',\n",
    ").update_layout(coloraxis_showscale=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 560
    },
    "id": "I91BytxbmoFH",
    "outputId": "e0eb72cd-6631-4211-f337-94a5951a3b99"
   },
   "outputs": [],
   "source": [
    "px.imshow(\n",
    "    dict(model.named_modules())['fc2'].weight.data,\n",
    "    width=1000, aspect='auto',\n",
    ").update_layout(coloraxis_showscale=False).show()\n",
    "print(dict(model.named_modules())['fc2'].weight.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pWg0UeB1ngAH"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
